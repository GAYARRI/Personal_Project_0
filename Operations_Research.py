import streamlit as st
import os
import glob
from pinecone import Pinecone, ServerlessSpec
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA  # ‚úÖ Importaci√≥n correct0
from langchain_openai import OpenAIEmbeddings  # ‚úÖ CORRECTO
from langchain_openai import ChatOpenAI  # ‚úÖ CORRECTO
from langchain_pinecone import PineconeVectorStore  # ‚úÖ CORRECTO


from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.memory import ConversationBufferMemory  # ‚úÖ CORRECTO
from langchain_community.tools import Tool
from langchain.agents import initialize_agent  # ‚úÖ CORRECTO
from langchain.agents import AgentType  # ‚úÖ CORRECTO
from langchain.memory import ConversationBufferMemory
from pinecone import Pinecone,ServerlessSpec
from dotenv import load_dotenv
import warnings



# Obtener API Key y entorno
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT")
INDEX_NAME = "operations-research"



# Inicializar modelo de embeddings y LLM
embedding = OpenAIEmbeddings()
llm = ChatOpenAI(model_name="gpt-4.5-preview", temperature=0.1)

# üîπ Cargar documentos solo una vez
@st.cache_resource
def load_documents(directory: str):
    """Carga y divide documentos PDF en fragmentos procesables."""
    documents = []
    pdf_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(".pdf")]

    if not pdf_files:
        raise FileNotFoundError("‚ùå No se encontraron archivos PDF en el directorio.")

    for pdf_file in pdf_files:
        loader = PyPDFLoader(pdf_file)
        docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(docs)
        documents.extend(texts)

    return documents

# Ruta de documentos (¬°Cambia esto a tu ruta real!)
DOCUMENTS_PATH = "C:/Users/gayar/Personal_Project/Documentos_Rag"
documents = load_documents(DOCUMENTS_PATH)

# üîπ Inicializar Pinecone solo una vez
@st.cache_resource
def get_vectorstore():
    """Carga o crea el vectorstore en Pinecone."""
    pc = Pinecone(api_key=PINECONE_API_KEY)
    
    if INDEX_NAME not in pc.list_indexes().names():
        pc.create_index(
            name=INDEX_NAME,
            dimension=1536,
            metric="euclidean",
            spec=ServerlessSpec(
                cloud="aws",
                region="eu-east1"
            )
        )

    return PineconeVectorStore.from_existing_index(INDEX_NAME, embedding)

vectorstore = get_vectorstore()

# üîπ Crear la cadena de b√∫squeda en documentos
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

# üîπ Crear herramienta de b√∫squeda
retrieval_tool = Tool(
    name="Research Retriever",
    func=qa_chain.run,
    description="Busca informaci√≥n en la base de datos de investigaci√≥n de operaciones."
)

# Verificar que la herramienta se haya creado correctamente
if retrieval_tool is None:
    raise ValueError("‚ùå La herramienta de b√∫squeda no se ha inicializado correctamente.")

# Lista de herramientas (debe contener al menos una)
tools = [retrieval_tool]
if not tools:
    raise ValueError("‚ùå No hay herramientas en la lista, el agente no podr√° funcionar.")

# üîπ Crear memoria del chatbot
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# üîπ Inicializar el agente con herramientas
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    memory=memory
)



# üîπ Interfaz en Streamlit
st.title("ü§ñ Hillier/Lieberman Corner")

user_input = st.text_input("‚úçÔ∏è What question do you have?")

if user_input:
    try:
        response = agent.invoke(user_input, handle_parsing_errors=True)
        output_text = response.get("output", "‚ö†Ô∏è No output generated.")

        # Mostrar la respuesta con formato Markdown
        st.markdown(f"### üìñ Answer:\n{output_text}", unsafe_allow_html=True)

    except Exception as e:
        st.error(f"üö® An error occurred: {e}")



